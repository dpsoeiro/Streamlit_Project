# -*- coding: utf-8 -*-
"""Model_Classificação.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jp_QbwhcjtFlMx2OR-o7_XIXthLGLuo5
"""


#from pycaret.clustering import *
import pandas as pd

from sklearn.feature_selection import VarianceThreshold
from sklearn.datasets import make_classification
import numpy as np

import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from scipy.spatial.distance import cdist
import lxml
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.metrics import calinski_harabasz_score
from sklearn.metrics.pairwise import cosine_similarity

from scipy.spatial.distance import cdist


"""# Tratamento de Dados"""

df_all_stats = pd.read_csv('df_all_stats_2023_2024.csv').drop(columns = ['Unnamed: 0'])
df_all_stats.head()

df_all_stats = pd.read_csv('df_all_stats_2022_2023.csv').drop(columns = ['Unnamed: 0'])
df_all_stats.head()

df_all_stats['Position_2'] = df_all_stats['Pos'].str[3:]
df_all_stats['Position'] = df_all_stats['Pos'].str[:2]

df_all_stats['Position'] = df_all_stats['Position'].replace({'MF': 'Midfielder', 'DF': 'Defender', 'FW': 'Forward', 'GK': 'Goalkeeper'})
df_all_stats['Position_2'] = df_all_stats['Position_2'].replace({'MF': 'Midfielder', 'DF': 'Defender',
                                                 'FW': 'Forward', 'GK': 'Goalkeeper'})

df_all_stats['Age'] = [age.split('-')[0] if '-' in age else age for age in df_all_stats['Age']]
df_all_stats['Age'] = [age.split('.')[0] if '.' in age else age for age in df_all_stats['Age']]
df_all_stats['Age'] = df_all_stats['Age'].astype('int')

df_all_stats.head()

df_all_stats.info()

df_halland = df_all_stats[df_all_stats['Player'].str.contains('Dušan Vlahović')].reset_index().drop(columns = ['index'])

df_halland

yng_plyr = df_all_stats[((df_all_stats['Age'] <= 17) & (df_all_stats['Age'] > 0)) ]
yng_plyr = yng_plyr[yng_plyr['Position'].str.contains('Forward')]#.reset_index().drop(columns = ['index'])
yng_plyr = df_halland.append(yng_plyr,ignore_index=True).reset_index().drop(columns = ['index']).fillna(yng_plyr.mean())
yng_plyr.head(20)

# Instancie o seletor de acordo com o limiar desejado (ajuste conforme necessário)
variance_selector = VarianceThreshold(threshold=0.5)
yng_plyr_int = yng_plyr.select_dtypes(include=['int', 'float64'])
X_selected = variance_selector.fit_transform(yng_plyr_int)

selected_features = np.array(np.where(variance_selector.get_support()))[0]
print("Características selecionadas:", selected_features)

yng_plyr_int = yng_plyr_int.iloc[:, selected_features]
yng_plyr = pd.merge(yng_plyr[['Player',	'Club', 'Position']], yng_plyr_int, left_index=True, right_index=True, how='left')

yng_plyr.head()

yng_plyr = yng_plyr.rename(columns = {'Age_x' : 'Age'})
yng_plyr.head()

#Aplicação de PCA

#yng_plyr.select_dtypes(include=['int', 'float64'])

x = yng_plyr.select_dtypes(include=['int', 'float64'])
scaler = StandardScaler()
x_scaled = scaler.fit_transform(x)
X_norm = pd.DataFrame(x_scaled)

pca = PCA(n_components=2)
reduced = pd.DataFrame(pca.fit_transform(X_norm))

reduced.head()

wcss=[]
for i in range(1,11):
    kmeans = KMeans(n_clusters=i, init ='k-means++', max_iter=300, n_init=10,random_state=0 )
    kmeans.fit(reduced)
    wcss.append(kmeans.inertia_)

plt.figure(figsize=(15, 10))

plt.plot(range(1,11),wcss)
plt.title('Previsão - Num Clusters Ideal')
plt.xlabel('Número de clusters')
plt.ylabel('WCSS')
plt.show()

from math import sqrt
def numero_otimo_clusters(wcss):
    x1, y1 = 1, wcss[0]
    x2, y2 = 10, wcss[len(wcss)-1]

    distances = []
    for i in range(len(wcss)):
        x0 = i+2
        y0 = wcss[i]
        numerator = abs((y2-y1)*x0 - (x2-x1)*y0 + x2*y1 - y2*x1)
        denominator = sqrt((y2 - y1)**2 + (x2 - x1)**2)
        distances.append(numerator/denominator)

    return distances.index(max(distances)) + 2

k_opt = numero_otimo_clusters(wcss)
print(k_opt)

## Specify the number of clusters
kmeans = KMeans(n_clusters=k_opt, init='k-means++', max_iter=600, random_state=42)

## Fit the input data
kmeans = kmeans.fit(reduced)

## Get the cluster labels
labels = kmeans.predict(reduced)

## Centroid values
centroid = kmeans.cluster_centers_

## Cluster values
clusters = kmeans.labels_.tolist()

names_fw = list(yng_plyr['Player'])

reduced['cluster'] = clusters


for column in list(yng_plyr.columns):
    reduced[column] = list(yng_plyr[column])

reduced

reduced = reduced.rename(columns = {0:'X',1:'Y'})

distance_matrix = pd.DataFrame(index=reduced['Player'], columns=reduced['Player'])
distance_matrix.head()

for i in range(len(distance_matrix)):
  x_i = reduced.iloc[i, 0]
  y_i = reduced.iloc[i, 1]
  for j in range(len(distance_matrix)):
    x_j = reduced.iloc[j, 0]
    y_j = reduced.iloc[j, 1]
    distance_matrix.iloc[i, j] = np.sqrt((x_i - x_j) ** 2 + (y_i - y_j) ** 2)

distance_matrix

similarity_matrix = pd.DataFrame(index=reduced['Player'], columns=reduced['Player'])
max_euc_distance = distance_matrix.max(axis=1)
for i in range(len(distance_matrix)):
  for j in range(len(distance_matrix)):
    similarity_matrix.iloc[i, j] = ((max_euc_distance[i]-distance_matrix.iloc[i, j])*100/max_euc_distance[i])

similarity_matrix

index_player = {name: index for index, name in enumerate(yng_plyr['Player'])}


player_name = 'Dušan Vlahović'
index = index_player[player_name]

scaler = StandardScaler()

data_players = yng_plyr.select_dtypes(include=['int', 'float64'])

data_players_normalized = scaler.fit_transform(data_players)

player_data = data_players.iloc[index].values.reshape(1, -1)
player_data_normalized = scaler.transform(player_data)
similarities = cosine_similarity(player_data_normalized, data_players_normalized)
similarities_converted = ((similarities + 1) / 2 * 100).round(1)

result_df = pd.DataFrame({
        'Player': yng_plyr['Player'],
        'Squad': yng_plyr['Club'],
        '% similarity': similarities_converted[0]
    })

result_df.sort_values(by='% similarity', ascending=False).to_csv('/content/drive/MyDrive/similarity2.csv')

result_df